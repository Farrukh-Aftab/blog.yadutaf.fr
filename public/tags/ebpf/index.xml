<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ebpf on Yet another enthusiast blog!</title>
    <link>http://blog.yadutaf.fr/tags/ebpf/</link>
    <description>Recent content in Ebpf on Yet another enthusiast blog!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Jul 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://blog.yadutaf.fr/tags/ebpf/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tracing a packet journey using Linux tracepoints, perf and eBPF</title>
      <link>http://blog.yadutaf.fr/2017/07/28/tracing-a-packet-journey-using-linux-tracepoints-perf-ebpf/</link>
      <pubDate>Fri, 28 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>http://blog.yadutaf.fr/2017/07/28/tracing-a-packet-journey-using-linux-tracepoints-perf-ebpf/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;ve been looking for a low level Linux network debugging tool for quite some time. Linux allows to build complex networks running directly on the host, using a combination of virtual interfaces and &lt;a href=&#34;http://blog.yadutaf.fr/2014/01/19/introduction-to-linux-namespaces-part-5-net/&#34;&gt;network namespaces&lt;/a&gt;. When something goes wrong, troubleshooting is rather tedious. If this is a L3 routing issue, &lt;code&gt;mtr&lt;/code&gt; has a good chance of being of some help. But if this is a lower level issue, I typically end up manually checking each interface / bridge / network namespace / iptables and firing up a couple of tcpdumps as an attempt to get a sense of what&amp;rsquo;s going on. If you have no prior knowledge of the network setup, this may feel like a maze.&lt;/p&gt;

&lt;p&gt;What I&amp;rsquo;d need is a tool which could tell me &amp;ldquo;Hey, I&amp;rsquo;ve seen your packet: It&amp;rsquo;s gone this way, on this interface, in this network namespace&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Basically, what I&amp;rsquo;d need is a &lt;code&gt;mtr&lt;/code&gt; for L2.&lt;/p&gt;

&lt;p&gt;Does not exist? Let&amp;rsquo;s build one!&lt;/p&gt;

&lt;p&gt;At the end of this post, we&amp;rsquo;ll have a simple and easy to use low level packet tracer. If you ping a local Docker container, it will show something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ping -4 172.17.0.2
[  4026531957]          docker0 request #17146.001 172.17.0.1 -&amp;gt; 172.17.0.2
[  4026531957]      vetha373ab6 request #17146.001 172.17.0.1 -&amp;gt; 172.17.0.2
[  4026532258]             eth0 request #17146.001 172.17.0.1 -&amp;gt; 172.17.0.2
[  4026532258]             eth0   reply #17146.001 172.17.0.2 -&amp;gt; 172.17.0.1
[  4026531957]      vetha373ab6   reply #17146.001 172.17.0.2 -&amp;gt; 172.17.0.1
[  4026531957]          docker0   reply #17146.001 172.17.0.2 -&amp;gt; 172.17.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tracing-to-the-rescue:722df47ecbedbece281b05064cb93eb9&#34;&gt;Tracing to the rescue&lt;/h3&gt;

&lt;p&gt;One way to get out of a maze, is by exploring. This is what you do when getting out of the maze is part of a game. Another way to get out is to shift your point of view, looking from above, and observing the path taken by those who know the path.&lt;/p&gt;

&lt;p&gt;In Linux terms, that would mean shifting to the kernel point of view, where network namespaces are just labels, instead of &amp;ldquo;containers&amp;rdquo;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:722df47ecbedbece281b05064cb93eb9:containers&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:722df47ecbedbece281b05064cb93eb9:containers&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. In the kernel, packets, interfaces and so on are plain observable objects.&lt;/p&gt;

&lt;p&gt;In this post, I&amp;rsquo;ll focus on 2 tracing tools. &lt;code&gt;perf&lt;/code&gt; and &lt;code&gt;eBPF&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;introducing-perf-and-ebpf:722df47ecbedbece281b05064cb93eb9&#34;&gt;Introducing &lt;code&gt;perf&lt;/code&gt; and &lt;code&gt;eBPF&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;perf&lt;/code&gt; is a the baseline tool for every performance related analysis on Linux. It is developed in the same source tree as the Linux kernel and must be specifically compiled for the kernel you will use to trace. It can trace the kernel as well as user programs. It may also work by sampling or using tracepoints. Think of it as a massive superset of &lt;code&gt;strace&lt;/code&gt; with a much lower overhead. We&amp;rsquo;ll use it only in a very simple way here. If you want to know more about &lt;code&gt;perf&lt;/code&gt;, I highly encourage you to &lt;a href=&#34;http://www.brendangregg.com/perf.html&#34;&gt;visit Brendan Gregg&amp;rsquo;s blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;eBPF&lt;/code&gt; is a relatively recent addition to the Linux Kernel. As its name suggests, this is an extended version of the BPF bytecode known as &amp;ldquo;Berkeley Packet Filter&amp;rdquo; used to&amp;hellip; filter packets on the BSD family. You name it. On Linux, it can also be used to safely run platform independent code in the live kernel, provided that it meets some safety criteria. For instance, memory accesses are validated BEFORE the program can run and it must be possible to prove that the program will end in a restricted amount of time. If the kernel can&amp;rsquo;t prove it, even if it&amp;rsquo;s safe and always terminates, it will be rejected.&lt;/p&gt;

&lt;p&gt;Such programs can be used as network classifier for QOS, very low level networking and filtering as part of eXpress Data Plane (XDP), as a tracing agent and many other places. Tracing probes can be attached to any function whose symbol is exported in &lt;code&gt;/proc/kallsyms&lt;/code&gt; or any tracepoints. In this post, I&amp;rsquo;ll focus on tracing agents attached to tracepoints.&lt;/p&gt;

&lt;p&gt;For an example of tracing probe attached to a kernel function or as a gentler introduction, I invite you to &lt;a href=&#34;http://blog.yadutaf.fr/2016/03/30/turn-any-syscall-into-event-introducing-ebpf-kernel-probes/&#34;&gt;read my previous post on eBPF&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;lab-setup:722df47ecbedbece281b05064cb93eb9&#34;&gt;Lab setup&lt;/h3&gt;

&lt;p&gt;For this post, we need &lt;code&gt;perf&lt;/code&gt; and some tools to work with eBPF. As I&amp;rsquo;m not a great fan of handwritten assembly, I&amp;rsquo;ll use &lt;a href=&#34;https://github.com/iovisor/bcc&#34;&gt;&lt;code&gt;bcc&lt;/code&gt;&lt;/a&gt; here. This is a powerful and flexible tool allowing you to write kernel probes as restricted C and instrument them in userland with Python. Heavyweight for production, but perfect for development!&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll reproduce here install instructions for Ubuntu 17.04 (Zesty) which is the OS powering my laptop. Instructions for &amp;ldquo;perf&amp;rdquo; should not diverge much from distributions to other and specific &lt;a href=&#34;https://github.com/iovisor/bcc/blob/master/INSTALL.md&#34;&gt;&lt;code&gt;bcc&lt;/code&gt; install instructions can be found on Github&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: attaching eBPF to tracepoints requires at least Linux kernel &amp;gt; 4.7.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Install &lt;code&gt;perf&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Grab &#39;perf&#39;
sudo apt install linux-tools-generic

# Test it
perf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you see an error message, it probably means that your kernel was updated recently but you did not reboot yet.&lt;/p&gt;

&lt;p&gt;Install &lt;code&gt;bcc&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install dependencies
sudo apt install bison build-essential cmake flex git libedit-dev python zlib1g-dev libelf-dev libllvm4.0 llvm-dev libclang-dev luajit luajit-5.1-dev

# Grab the sources
git clone https://github.com/iovisor/bcc.git

# Build and install
mkdir bcc/build
cd bcc/build
cmake .. -DCMAKE_INSTALL_PREFIX=/usr
make
sudo make install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;finding-good-tracepoints-aka-as-manually-tracing-a-packet-s-journey-with-perf:722df47ecbedbece281b05064cb93eb9&#34;&gt;Finding good tracepoints aka as &amp;ldquo;manually tracing a packet&amp;rsquo;s journey with &lt;code&gt;perf&lt;/code&gt;&amp;ldquo;&lt;/h3&gt;

&lt;p&gt;There are multiple ways to find good tracepoints. In a previous version of this post, I started from the code of the &lt;code&gt;veth&lt;/code&gt; driver and followed the trail from there to find functions to trace. While it did lead to acceptable results, I could not catch all the packets. Indeed, the common paths crossed by all packets are in un-exported (inline or static) methods. This is also when I realized Linux had tracepoints and decided to rewrite this post and the associated code using tracepoints instead. This was quite frustrating, but also much more interesting (to me).&lt;/p&gt;

&lt;p&gt;Enough talks on myself, back to work.&lt;/p&gt;

&lt;p&gt;The goal is to trace the path taken by a packet. Depending on the crossed interfaces, the crossed tracepoints may differ (spoiler alert: they do).&lt;/p&gt;

&lt;p&gt;To find suitable tracepoints, I used ping with 2 internal and 2 external targets under &lt;code&gt;perf trace&lt;/code&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;localhost with IP &lt;em&gt;127.0.0.1&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;An innocent Docker container with IP &lt;em&gt;172.17.0.2&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;My phone via USB tethering with IP &lt;em&gt;192.168.42.129&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;My phone via WiFi with IP &lt;em&gt;192.168.43.1&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;perf trace&lt;/code&gt; is a sub command of perf, which produces an output similar to strace (with a MUCH lower overhead) by default. We can easily tweak it to hide the syscalls themselves and instead print events of the &amp;lsquo;net&amp;rsquo; category. For instance, tracing a ping to a Docker container with IP 172.17.0.2 would look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo perf trace --no-syscalls --event &#39;net:*&#39; ping 172.17.0.2 -c1 &amp;gt; /dev/null
     0.000 net:net_dev_queue:dev=docker0 skbaddr=0xffff96d481988700 len=98)
     0.008 net:net_dev_start_xmit:dev=docker0 queue_mapping=0 skbaddr=0xffff96d481988700 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=0 len=98 data_len=0 network_offset=14 transport_offset_valid=1 transport_offset=34 tx_flags=0 gso_size=0 gso_segs=0 gso_type=0)
     0.014 net:net_dev_queue:dev=veth79215ff skbaddr=0xffff96d481988700 len=98)
     0.016 net:net_dev_start_xmit:dev=veth79215ff queue_mapping=0 skbaddr=0xffff96d481988700 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=0 len=98 data_len=0 network_offset=14 transport_offset_valid=1 transport_offset=34 tx_flags=0 gso_size=0 gso_segs=0 gso_type=0)
     0.020 net:netif_rx:dev=eth0 skbaddr=0xffff96d481988700 len=84)
     0.022 net:net_dev_xmit:dev=veth79215ff skbaddr=0xffff96d481988700 len=98 rc=0)
     0.024 net:net_dev_xmit:dev=docker0 skbaddr=0xffff96d481988700 len=98 rc=0)
     0.027 net:netif_receive_skb:dev=eth0 skbaddr=0xffff96d481988700 len=84)
     0.044 net:net_dev_queue:dev=eth0 skbaddr=0xffff96d481988b00 len=98)
     0.046 net:net_dev_start_xmit:dev=eth0 queue_mapping=0 skbaddr=0xffff96d481988b00 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=0 len=98 data_len=0 network_offset=14 transport_offset_valid=1 transport_offset=34 tx_flags=0 gso_size=0 gso_segs=0 gso_type=0)
     0.048 net:netif_rx:dev=veth79215ff skbaddr=0xffff96d481988b00 len=84)
     0.050 net:net_dev_xmit:dev=eth0 skbaddr=0xffff96d481988b00 len=98 rc=0)
     0.053 net:netif_receive_skb:dev=veth79215ff skbaddr=0xffff96d481988b00 len=84)
     0.060 net:netif_receive_skb_entry:dev=docker0 napi_id=0x3 queue_mapping=0 skbaddr=0xffff96d481988b00 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=2 hash=0x00000000 l4_hash=0 len=84 data_len=0 truesize=768 mac_header_valid=1 mac_header=-14 nr_frags=0 gso_size=0 gso_type=0)
     0.061 net:netif_receive_skb:dev=docker0 skbaddr=0xffff96d481988b00 len=84)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Keeping only the event names and skbaddr, this looks more readable.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;net_dev_queue           dev=docker0     skbaddr=0xffff96d481988700
net_dev_start_xmit      dev=docker0     skbaddr=0xffff96d481988700
net_dev_queue           dev=veth79215ff skbaddr=0xffff96d481988700
net_dev_start_xmit      dev=veth79215ff skbaddr=0xffff96d481988700
netif_rx                dev=eth0        skbaddr=0xffff96d481988700
net_dev_xmit            dev=veth79215ff skbaddr=0xffff96d481988700
net_dev_xmit            dev=docker0     skbaddr=0xffff96d481988700
netif_receive_skb       dev=eth0        skbaddr=0xffff96d481988700

net_dev_queue           dev=eth0        skbaddr=0xffff96d481988b00
net_dev_start_xmit      dev=eth0        skbaddr=0xffff96d481988b00
netif_rx                dev=veth79215ff skbaddr=0xffff96d481988b00
net_dev_xmit            dev=eth0        skbaddr=0xffff96d481988b00
netif_receive_skb       dev=veth79215ff skbaddr=0xffff96d481988b00
netif_receive_skb_entry dev=docker0     skbaddr=0xffff96d481988b00
netif_receive_skb       dev=docker0     skbaddr=0xffff96d481988b00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are multiple things to be said here. The most obvious being that the &lt;code&gt;skbaddr&lt;/code&gt; changes in the middle, but stays the same otherwise. This is when the echo reply packet is generated as a reply to this echo request (ping). The rest of the time, the same network packet is moved between interfaces, with hopefully no copy. Copying is expensive&amp;hellip;&lt;/p&gt;

&lt;p&gt;The other interesting point is, we clearly see the packet going through the &lt;code&gt;docker0&lt;/code&gt; bridge, then the host side of the veth, &lt;code&gt;veth79215ff&lt;/code&gt; in my case, and finally the container side of the veth, pretending to be &lt;code&gt;eth0&lt;/code&gt;. We don&amp;rsquo;t see the network namespaces yet, but it already gives a good overview.&lt;/p&gt;

&lt;p&gt;Finally, after seeing the packet on &lt;code&gt;eth0&lt;/code&gt; we hit tracepoints in reverse order. This is not the response, but the finalization of the transmission.&lt;/p&gt;

&lt;p&gt;By repeating a similar process on the 4 target scenarios, we can pick the most appropriate tracing points to track our packet&amp;rsquo;s journey. I picked 4 of them:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;net_dev_queue&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;netif_receive_skb_entry&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;netif_rx&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;napi_gro_receive_entry&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Taking these 4 tracepoints will give me trace events in order with no duplication, saving some de-duplication work. Still good to take.&lt;/p&gt;

&lt;p&gt;We can easily double check this selection like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo perf trace --no-syscalls           \
  --event &#39;net:net_dev_queue&#39;           \
  --event &#39;net:netif_receive_skb_entry&#39; \
  --event &#39;net:netif_rx&#39;                \
  --event &#39;net:napi_gro_receive_entry&#39;  \
  ping 172.17.0.2 -c1 &amp;gt; /dev/null
     0.000 net:net_dev_queue:dev=docker0 skbaddr=0xffff8e847720a900 len=98)
     0.010 net:net_dev_queue:dev=veth7781d5c skbaddr=0xffff8e847720a900 len=98)
     0.014 net:netif_rx:dev=eth0 skbaddr=0xffff8e847720a900 len=84)
     0.034 net:net_dev_queue:dev=eth0 skbaddr=0xffff8e849cb8cd00 len=98)
     0.036 net:netif_rx:dev=veth7781d5c skbaddr=0xffff8e849cb8cd00 len=84)
     0.045 net:netif_receive_skb_entry:dev=docker0 napi_id=0x1 queue_mapping=0 skbaddr=0xffff8e849cb8cd00 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=2 hash=0x00000000 l4_hash=0 len=84 data_len=0 truesize=768 mac_header_valid=1 mac_header=-14 nr_frags=0 gso_size=0 gso_type=0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mission accomplished!&lt;/p&gt;

&lt;p&gt;If you want to go further and explore a list of available network tracepoints, you may user &lt;code&gt;perf list&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo perf list &#39;net:*&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should return a list of tracepoints names like &lt;code&gt;net:netif_rx&lt;/code&gt;. The part before the colon (&amp;rsquo;:&amp;lsquo;) is the event category (&amp;lsquo;net&amp;rsquo;). The part after is the event name, in this category.&lt;/p&gt;

&lt;h3 id=&#34;writing-a-custom-tracer-with-ebpf-bcc:722df47ecbedbece281b05064cb93eb9&#34;&gt;Writing a custom tracer with &lt;code&gt;eBPF&lt;/code&gt; / &lt;code&gt;bcc&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;This would be more than enough for most situations. If you were reading this post to learn how to trace a packet&amp;rsquo;s journey on a Linux box, you already got all you need. But, if you want to dive deeper, run a custom filter, track more data like the network namespaces crossed by the packets or the source and destination IPs, please, bear with me.&lt;/p&gt;

&lt;p&gt;Starting with Linux Kernel 4.7, eBPF programs can be attached to kernel tracepoints. Before that, the only alternative to build this tracer would have been to attach the probes to exported kernel symbols. While this could work, it would have a couple of drawbacks:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The kernel internal API is not stable. Tracepoints are (although the data structures ae not necessarily&amp;hellip;).&lt;/li&gt;
&lt;li&gt;For performance reasons, most of the networking inner functions are inlined or static. Neither of which can be probed.&lt;/li&gt;
&lt;li&gt;It is tedious to find all potential call sites for this functions, and sometime not all required data is available at this stage.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;An earlier version of this post attempted to use kprobes, which are easier to use, but the results were at best incomplete.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s be honest, accessing data via tracepoints is a lot more tedious than with there kprobe counterpart. While I tried to keep this post as gentle as possible, you may want to start with the (slightly older) post &lt;a href=&#34;http://blog.yadutaf.fr/2016/03/30/turn-any-syscall-into-event-introducing-ebpf-kernel-probes/&#34;&gt;&amp;ldquo;How to turn any syscall into an event: Introducing eBPF Kernel probes&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This disclaimer aside, let&amp;rsquo;s start with a simple hello world and get the low level plumbing into place. In this hello world, we&amp;rsquo;ll build an event every time 1 of the 4 tracepoints we chose earlier (&lt;code&gt;net_dev_queue&lt;/code&gt;, &lt;code&gt;netif_receive_skb_entry&lt;/code&gt;, &lt;code&gt;netif_rx&lt;/code&gt; and &lt;code&gt;napi_gro_receive_entry&lt;/code&gt;) is triggered. To keep things simple at this stage, we&amp;rsquo;ll send the program&amp;rsquo;s &lt;code&gt;comm&lt;/code&gt;, that is, a 16 char string that&amp;rsquo;s basically the program name.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;bcc/proto.h&amp;gt;
#include &amp;lt;linux/sched.h&amp;gt;

// Event structure
struct route_evt_t {
        char comm[TASK_COMM_LEN];
};
BPF_PERF_OUTPUT(route_evt);

static inline int do_trace(void* ctx, struct sk_buff* skb)
{
    // Built event for userland
    struct route_evt_t evt = {};
    bpf_get_current_comm(evt.comm, TASK_COMM_LEN);

    // Send event to userland
    route_evt.perf_submit(ctx, &amp;amp;evt, sizeof(evt));

    return 0;
}

/**
  * Attach to Kernel Tracepoints
  */

TRACEPOINT_PROBE(net, netif_rx) {
    return do_trace(args, (struct sk_buff*)args-&amp;gt;skbaddr);
}

TRACEPOINT_PROBE(net, net_dev_queue) {
    return do_trace(args, (struct sk_buff*)args-&amp;gt;skbaddr);
}

TRACEPOINT_PROBE(net, napi_gro_receive_entry) {
    return do_trace(args, (struct sk_buff*)args-&amp;gt;skbaddr);
}

TRACEPOINT_PROBE(net, netif_receive_skb_entry) {
    return do_trace(args, (struct sk_buff*)args-&amp;gt;skbaddr);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This snippet attaches to the 4 tracepoints of the &amp;ldquo;net&amp;rdquo; category, loads the &lt;code&gt;skbaddr&lt;/code&gt; field and passes it to the common section which only loads the program name for now. If you wonder where this &lt;code&gt;args-&amp;gt;skbaddr&lt;/code&gt; come from (and I&amp;rsquo;d be glad you do), the &lt;code&gt;args&lt;/code&gt; structure is generated for you by bcc whenever you define a tracepoint with &lt;code&gt;TRACEPOINT_PROBE&lt;/code&gt;. As it is generated on the fly, there is no easy way to see its definition BUT, there is a better way. We can directly look at the data source, from the kernel. Fortunately there is a &lt;code&gt;/sys/kernel/debug/tracing/events&lt;/code&gt; entry for each tracepoint. For instance, for the &lt;code&gt;net:netif_rx&lt;/code&gt;, one could just &amp;ldquo;cat&amp;rdquo; &lt;code&gt;/sys/kernel/debug/tracing/events/net/netif_rx/format&lt;/code&gt; which should output something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;name: netif_rx
ID: 1183
format:
	field:unsigned short common_type;         offset:0; size:2; signed:0;
	field:unsigned char common_flags;         offset:2; size:1; signed:0;
	field:unsigned char common_preempt_count; offset:3; size:1; signed:0;
	field:int common_pid;                     offset:4; size:4; signed:1;

	field:void * skbaddr;         offset:8;  size:8; signed:0;
	field:unsigned int len;       offset:16; size:4; signed:0;
	field:__data_loc char[] name; offset:20; size:4; signed:1;

print fmt: &amp;quot;dev=%s skbaddr=%p len=%u&amp;quot;, __get_str(name), REC-&amp;gt;skbaddr, REC-&amp;gt;len
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You may notice the &lt;code&gt;print fmt&lt;/code&gt; line at the end of the record. This is exactly what&amp;rsquo;s used by &lt;code&gt;perf trace&lt;/code&gt; to generate its output.&lt;/p&gt;

&lt;p&gt;With the low level plumbing in place and well understood, we can wrap it in a Python script to display a line for every event send by the eBPF side of the probe:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python
# coding: utf-8

from socket import inet_ntop
from bcc import BPF
import ctypes as ct

bpf_text = &#39;&#39;&#39;&amp;lt;SEE CODE SNIPPET ABOVE&amp;gt;&#39;&#39;&#39;

TASK_COMM_LEN = 16 # linux/sched.h

class RouteEvt(ct.Structure):
    _fields_ = [
        (&amp;quot;comm&amp;quot;,    ct.c_char * TASK_COMM_LEN),
    ]

def event_printer(cpu, data, size):
    # Decode event
    event = ct.cast(data, ct.POINTER(RouteEvt)).contents

    # Print event
    print &amp;quot;Just got a packet from %s&amp;quot; % (event.comm)

if __name__ == &amp;quot;__main__&amp;quot;:
    b = BPF(text=bpf_text)
    b[&amp;quot;route_evt&amp;quot;].open_perf_buffer(event_printer)

    while True:
        b.kprobe_poll()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You may test it now. You will need to be root.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: There is no filtering at this stage. Even a low background network usage may flood your terminal!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;$&amp;gt; sudo python ./tracepkt.py
...
Just got a packet from ping6
Just got a packet from ping6
Just got a packet from ping
Just got a packet from irq/46-iwlwifi
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case, you can see that I was using ping and ping6 and the WiFi driver just received some packets. In that case, that was the echo reply.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start adding some useful data / filters.&lt;/p&gt;

&lt;p&gt;I will not focus on performance in this post. This will better demonstrate the the power and limitations of eBPF. To make it (much) faster, we could use the packet size as a heuristic, assuming there is no strange IP options. Using the example programs as is will slow down your network traffic.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: to limit the length of this post, I&amp;rsquo;ll focus on the C/eBPF part here. I&amp;rsquo;ll put a link to the full source code at the end of this post.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;add-in-network-interface-information:722df47ecbedbece281b05064cb93eb9&#34;&gt;Add in network interface information&lt;/h3&gt;

&lt;p&gt;First, you can safely remove the &amp;ldquo;comm&amp;rdquo; fields, loading and sched.h header. It&amp;rsquo;s of no real use here, sorry.&lt;/p&gt;

&lt;p&gt;Then you can include &lt;code&gt;net/inet_sock.h&lt;/code&gt; so that we have all necessary declarations and add &lt;code&gt;char ifname[IFNAMSIZ];&lt;/code&gt; to the event structure.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll now load the device name from the device structure. This is interesting as this is an actually useful piece of information and it demonstrates on a manageable scale the techniques to load any data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Get device pointer, we&#39;ll need it to get the name and network namespace
struct net_device *dev;
bpf_probe_read(&amp;amp;dev, sizeof(skb-&amp;gt;dev), ((char*)skb) + offsetof(typeof(*skb), dev));

// Load interface name
bpf_probe_read(&amp;amp;evt.ifname, IFNAMSIZ, dev-&amp;gt;name);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can test it, it works as is. Do not forget to add the related part on the Python side though :)&lt;/p&gt;

&lt;p&gt;OK, so how does it work? To load the interface name, we need the interface device structure. I&amp;rsquo;ll start from the last statement as it&amp;rsquo;s the easiest to understand and the previous one is actually just or trickier version. It uses &lt;code&gt;bpf_probe_read&lt;/code&gt; to read data of length &lt;code&gt;IFNAMSIZ&lt;/code&gt; from &lt;code&gt;dev-&amp;gt;name&lt;/code&gt; and copy it to &lt;code&gt;evt.ifname&lt;/code&gt;. The fist line follows exactly the same logic. It loads the value of the &lt;code&gt;skb-&amp;gt;dev&lt;/code&gt; pointer into &lt;code&gt;dev&lt;/code&gt;. Unfortunately, I could not find another way to load the field address without this nice offsetof / typeof tricks.&lt;/p&gt;

&lt;p&gt;As a reminder, the goal of eBPF is to allow &lt;em&gt;safe&lt;/em&gt; scripting of the kernel. This implies that random memory access are forbidden. All memory accesses must be validated. Unless the memory you access in on the stack, you need to use the &lt;code&gt;bpf_probe_read&lt;/code&gt; read accessor. This makes to code cumbersome to read / write but makes it safe too. &lt;code&gt;bpf_probe_read&lt;/code&gt; is somehow like a safe version of &lt;code&gt;memcpy&lt;/code&gt;. It is defined in &lt;a href=&#34;http://elixir.free-electrons.com/linux/v4.10.17/source/kernel/trace/bpf_trace.c#L64&#34;&gt;bpf_trace.c in the kernel&lt;/a&gt;. The interesting parts being:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;It&amp;rsquo;s like memcpy. Beware of the cost of copies on performance.&lt;/li&gt;
&lt;li&gt;In case of error, it will return a buffer initialized to 0 and return an error. It will &lt;em&gt;not&lt;/em&gt; crash or stop the program.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For the remaining parts of this post, I&amp;rsquo;ll use the following macro to help keep things readable:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define member_read(destination, source_struct, source_member)                 \
  do{                                                                          \
    bpf_probe_read(                                                            \
      destination,                                                             \
      sizeof(source_struct-&amp;gt;source_member),                                    \
      ((char*)source_struct) + offsetof(typeof(*source_struct), source_member) \
    );                                                                         \
  } while(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which allows us to write:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;member_read(&amp;amp;dev, skb, dev);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s better!&lt;/p&gt;

&lt;h3 id=&#34;add-in-the-network-namespace-id:722df47ecbedbece281b05064cb93eb9&#34;&gt;Add in the network namespace ID&lt;/h3&gt;

&lt;p&gt;That&amp;rsquo;s probably the most valuable piece of information. In itself, it is a valid reason to all these efforts. Unfortunately, this is also the hardest to load.&lt;/p&gt;

&lt;p&gt;The namespace identifier can be loaded from 2 places:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;the socket &amp;lsquo;sk&amp;rsquo; structure&lt;/li&gt;
&lt;li&gt;the device &amp;lsquo;dev&amp;rsquo; structure&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I was initially using the socket structure as this is the one I was using when writing &lt;a href=&#34;https://github.com/iovisor/bcc/blob/master/tools/solisten.py&#34;&gt;solisten.py&lt;/a&gt;. Unfortunately, and I&amp;rsquo;m not sure why, the namespace identifier is no longer readable as soon as the packet crosses a namespace boundary. The field is all 0s, which is a clear indicator of an invalid memory access (remember how bpf_probe_read works in case of errors) and defeats the whole point.&lt;/p&gt;

&lt;p&gt;Fortunately, the device approach works. Think of it like asking the packet on which interface it is and asking the interface in which namespace it belongs.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct net* net;

// Get netns id. Equivalent to: evt.netns = dev-&amp;gt;nd_net.net-&amp;gt;ns.inum
possible_net_t *skc_net = &amp;amp;dev-&amp;gt;nd_net;
member_read(&amp;amp;net, skc_net, net);
struct ns_common* ns = member_address(net, ns);
member_read(&amp;amp;evt.netns, ns, inum);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which uses the following additional macro for improved readability:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define member_address(source_struct, source_member) \
({                                                   \
  void* __ret;                                       \
  __ret = (void*) (((char*)source_struct) + offsetof(typeof(*source_struct), source_member)); \
  __ret;                                             \
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As a side effect, it allows to simplify the &lt;code&gt;member_read&lt;/code&gt; macro. I&amp;rsquo;ll leave it as an exercise for the reader.&lt;/p&gt;

&lt;p&gt;Plug this together, and&amp;hellip; Tadaa!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$&amp;gt; sudo python ./tracepkt.py
[  4026531957]          docker0
[  4026531957]      vetha373ab6
[  4026532258]             eth0
[  4026532258]             eth0
[  4026531957]      vetha373ab6
[  4026531957]          docker0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is what you should see if you send a ping to a Docker container. The packet goes through the local &lt;code&gt;docker0&lt;/code&gt; bridge and then moves to the the &lt;code&gt;veth&lt;/code&gt; pair, crossing the network namespace boundary and the reply follows the exact reverse path.&lt;/p&gt;

&lt;p&gt;That was a nasty one!&lt;/p&gt;

&lt;h3 id=&#34;going-further-trace-only-requests-reply-and-echo-replies-packets:722df47ecbedbece281b05064cb93eb9&#34;&gt;Going further: trace only requests reply and echo replies packets&lt;/h3&gt;

&lt;p&gt;As a bonus, we&amp;rsquo;ll also load the IP from the packets. We have to read the IP header anyway. I&amp;rsquo;ll stick to IPv4 here, but the same logic applies for IPv6.&lt;/p&gt;

&lt;p&gt;Bad news is, nothing is really simple. Remember, we are dealing with the kernel, in the network path. Some packets have not yet been opened. This means that some headers offsets are still uninitialized. We&amp;rsquo;ll have to compute all of them, going from the MAC header to the IP header and finally to the ICMP header.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start gently by loading the MAC header address and deducing the IP header address. We won&amp;rsquo;t load the MAC header itself and instead assume it is 14 bytes long.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Compute MAC header address
char* head;
u16 mac_header;

member_read(&amp;amp;head,       skb, head);
member_read(&amp;amp;mac_header, skb, mac_header);

// Compute IP Header address
#define MAC_HEADER_SIZE 14;
char* ip_header_address = head + mac_header + MAC_HEADER_SIZE;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This basically means that the IP header starts at &lt;code&gt;skb-&amp;gt;head + skb-&amp;gt;mac_header + MAC_HEADER_SIZE;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We can now decode the IP version in the first 4 bits of the IP header, that is, the first half of the first byte, and make sure it is IPv4:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Load IP protocol version
u8 ip_version;
bpf_probe_read(&amp;amp;ip_version, sizeof(u8), ip_header_address);
ip_version = ip_version &amp;gt;&amp;gt; 4 &amp;amp; 0xf;

// Filter IPv4 packets
if (ip_version != 4) {
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now load the full IP header, grab the IPs to make the Python info even more useful, make sure the next header is ICMP and derive the ICMP header offset. Yes all this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Load IP Header
struct iphdr iphdr;
bpf_probe_read(&amp;amp;iphdr, sizeof(iphdr), ip_header_address);

// Load protocol and address
u8 icmp_offset_from_ip_header = iphdr.ihl * 4;
evt.saddr[0] = iphdr.saddr;
evt.daddr[0] = iphdr.daddr;

// Filter ICMP packets
if (iphdr.protocol != IPPROTO_ICMP) {
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we can load the ICMP header itself, make sure this is an echo request of reply and load the id and seq from it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Compute ICMP header address and load ICMP header
char* icmp_header_address = ip_header_address + icmp_offset_from_ip_header;
struct icmphdr icmphdr;
bpf_probe_read(&amp;amp;icmphdr, sizeof(icmphdr), icmp_header_address);

// Filter ICMP echo request and echo reply
if (icmphdr.type != ICMP_ECHO &amp;amp;&amp;amp; icmphdr.type != ICMP_ECHOREPLY) {
    return 0;
}

// Get ICMP info
evt.icmptype = icmphdr.type;
evt.icmpid   = icmphdr.un.echo.id;
evt.icmpseq  = icmphdr.un.echo.sequence;

// Fix endian
evt.icmpid  = be16_to_cpu(evt.icmpid);
evt.icmpseq = be16_to_cpu(evt.icmpseq);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s all folks!&lt;/p&gt;

&lt;p&gt;If you want to filter ICMP from a specific ping instance, you may assume &lt;code&gt;evt.icmpid&lt;/code&gt; &lt;a href=&#34;https://github.com/iputils/iputils/blob/master/ping_common.c&#34;&gt;is the PID of the ping&lt;/a&gt; at least using Linux&amp;rsquo;s ping.&lt;/p&gt;

&lt;h3 id=&#34;show-time:722df47ecbedbece281b05064cb93eb9&#34;&gt;Show time!&lt;/h3&gt;

&lt;p&gt;With some straightforward Python to handle the event, we can test it in a couple of scenarios. Start the program as root, launch some &amp;ldquo;ping&amp;rdquo; in another terminal and observe:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ping -4 localhost
[  4026531957]               lo request #20212.001 127.0.0.1 -&amp;gt; 127.0.0.1
[  4026531957]               lo request #20212.001 127.0.0.1 -&amp;gt; 127.0.0.1
[  4026531957]               lo   reply #20212.001 127.0.0.1 -&amp;gt; 127.0.0.1
[  4026531957]               lo   reply #20212.001 127.0.0.1 -&amp;gt; 127.0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An ICMP echo request is sent by process 20212 (the ICMP id on Linux&amp;rsquo;s ping) on the loopback interface, delivered to the very same loopback interface where an echo reply is generated and sent back. The loopback interface is both the emitting and receiving interface.&lt;/p&gt;

&lt;p&gt;What about my WiFi gateway?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ping -4 192.168.43.1
[  4026531957]           wlp2s0 request #20710.001 192.168.43.191 -&amp;gt; 192.168.43.1
[  4026531957]           wlp2s0   reply #20710.001 192.168.43.1 -&amp;gt; 192.168.43.191
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case, the echo request and echo reply go through the WiFi interface. Easy.&lt;/p&gt;

&lt;p&gt;On a slightly unrelated note, remember when we were only printing the &amp;ldquo;comm&amp;rdquo; of the process owning the packet? In this case, the echo request would belong to ping process while the reply would belong to the WiFi driver as this is the one generating it as far as Linux is concerned.&lt;/p&gt;

&lt;p&gt;And the last one, my personal favorite, ping a Docker container. It&amp;rsquo;s not my favorite because of Docker. It is my favorite because it best shows the the power of eBPF. It allowed to build an &amp;ldquo;x-ray&amp;rdquo; like tool for ping.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ping -4 172.17.0.2
[  4026531957]          docker0 request #17146.001 172.17.0.1 -&amp;gt; 172.17.0.2
[  4026531957]      vetha373ab6 request #17146.001 172.17.0.1 -&amp;gt; 172.17.0.2
[  4026532258]             eth0 request #17146.001 172.17.0.1 -&amp;gt; 172.17.0.2
[  4026532258]             eth0   reply #17146.001 172.17.0.2 -&amp;gt; 172.17.0.1
[  4026531957]      vetha373ab6   reply #17146.001 172.17.0.2 -&amp;gt; 172.17.0.1
[  4026531957]          docker0   reply #17146.001 172.17.0.2 -&amp;gt; 172.17.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With some art, it now looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       Host netns           | Container netns
+---------------------------+-----------------+
| docker0 ---&amp;gt; veth0e65931 ---&amp;gt; eth0          |
+---------------------------+-----------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;final-word:722df47ecbedbece281b05064cb93eb9&#34;&gt;Final word&lt;/h3&gt;

&lt;p&gt;eBPF/bcc enables us to write a new range of tools to deeply troubleshoot, trace and track issues in places previously unreachable without patching the kernel. Tracepoints are also quite handy as they give a good hint on interesting places, removing the need to tediously read the kernel code and can be placed in portions of the code that would otherwise be unreachable from kprobes, like inline or static functions.&lt;/p&gt;

&lt;p&gt;To go further, we could add IPv6 support. This is quite easy to do and I&amp;rsquo;ll leave it as an exercise for the reader. Ideally, I&amp;rsquo;d like to measure the impact on performance as well. But this post is already very, very long. It could be interesting to improve this tool by tracing routing and iptables decisions and tracing ARP packets. All this would turn this tool into a perfect &amp;ldquo;x-ray&amp;rdquo; packet tracer for people like me, sometime struggling with non-trivial Linux network setups.&lt;/p&gt;

&lt;p&gt;As promised, you can see the full code (with IPv6 support) on Github:  &lt;a href=&#34;https://github.com/yadutaf/tracepkt&#34;&gt;https://github.com/yadutaf/tracepkt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Finally, I&amp;rsquo;d like to acknowledge the help of &lt;a href=&#34;https://twitter.com/fcabestre&#34;&gt;@fcabestre&lt;/a&gt; who helped me rescue the working draft of this post from a malfunctioning hard disk, &lt;a href=&#34;https://twitter.com/bluxte&#34;&gt;@bluxte&lt;/a&gt; for his patient proof reading and the people of &lt;a href=&#34;https://github.com/iovisor/bcc&#34;&gt;bcc&lt;/a&gt; who made this post technically possible.&lt;/p&gt;

&lt;h3 id=&#34;note-s:722df47ecbedbece281b05064cb93eb9&#34;&gt;Note(s)&lt;/h3&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:722df47ecbedbece281b05064cb93eb9:containers&#34;&gt;I&amp;rsquo;ve put &amp;ldquo;containers&amp;rdquo; into quotes as, technically speaking, network namespaces are one of the many building blocks of Linux containers.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:722df47ecbedbece281b05064cb93eb9:containers&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to turn any syscall into an event: Introducing eBPF Kernel probes</title>
      <link>http://blog.yadutaf.fr/2016/03/30/turn-any-syscall-into-event-introducing-ebpf-kernel-probes/</link>
      <pubDate>Wed, 30 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>http://blog.yadutaf.fr/2016/03/30/turn-any-syscall-into-event-introducing-ebpf-kernel-probes/</guid>
      <description>

&lt;p&gt;TL;DR: Using eBPF in recent (&amp;gt;=4.4) Linux kernel, you can turn any kernel function call into a user land event with arbitrary data. This is made easy by bcc. The probe is written in C while the data is handled by python.&lt;/p&gt;

&lt;p&gt;If you are not familiar with eBPF or linux tracing, you really should read the full post. It tries to progressively go through the pitfalls I stumbled unpon while playing around with bcc / eBPF while saving you a lot of the time I spent searching and digging.&lt;/p&gt;

&lt;h3 id=&#34;a-note-on-push-vs-pull-in-a-linux-world:30fe7a87f2e63f2b769ee3edffa56012&#34;&gt;A note on push vs pull in a Linux world&lt;/h3&gt;

&lt;p&gt;When I started to work on containers, I was wondering how we could update a load balancer configuration dynamically based on actual system state. A common strategy, which works, it to let the container orchestrator trigger a load balancer configuration update whenever it starts a container and then let the load balancer poll the container until some health check passes. It may be a simple &amp;ldquo;SYN&amp;rdquo; test.&lt;/p&gt;

&lt;p&gt;While this configuration works, it has the downside of making your load balancer waiting for some system to be available while it should be&amp;hellip; load balancing.&lt;/p&gt;

&lt;p&gt;Can we do better?&lt;/p&gt;

&lt;p&gt;When you want a program to react to some change in a system there are 2 possible strategies. The program may &lt;em&gt;poll&lt;/em&gt; the system to detect changes or, if the system supports it, the system may &lt;em&gt;push&lt;/em&gt; events and let the program react to them. Wether you want to use push or poll depends on the context. A good rule of the thumb is to use push events when the event rate is low with respect to the processing time and switch to polling when the events are coming fast or the system may become unusable. For example, typical network driver will wait for events from the network card while frameworks like dpdk will actively poll the card for events to achieve the highest throughput and lowest latency.&lt;/p&gt;

&lt;p&gt;In an ideal world, we&amp;rsquo;d have some kernel interface telling us:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Hey Mr. ContainerManager, I&amp;rsquo;ve just created a socket for the Nginx-ware of container &lt;em&gt;servestaticfiles&lt;/em&gt;, maybe you want to update your state?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Sure Mr. OS, Thanks for letting me know&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;While Linux has a wide range of interfaces to deal with events, up to 3 for file events, there is no dedicated interface to get socket event notifications. You can get routing table events, neighbor table events, conntrack events, interface change events. Just, not socket events. Or maybe there is, deep hidden in a Netlink interface.&lt;/p&gt;

&lt;p&gt;Ideally, we&amp;rsquo;d need a generic way to do it. How?&lt;/p&gt;

&lt;h3 id=&#34;kernel-tracing-and-ebpf-a-bit-of-history:30fe7a87f2e63f2b769ee3edffa56012&#34;&gt;Kernel tracing and eBPF, a bit of history&lt;/h3&gt;

&lt;p&gt;Until recently the only way was to patch the kernel or resort on SystemTap. &lt;a href=&#34;https://en.wikipedia.org/wiki/SystemTap&#34;&gt;SytemTap&lt;/a&gt; is a tracing Linux system. In a nutshell, it provides a DSL which is then compiled into a kernel module which is then live-loaded into the running kernel. Except that some production system disable dynamic module loading for security reasons. Including the one I was working on at that time. The other way would be to patch the kernel to trigger some events, probably based on netlink. This is not really convenient. Kernel hacking come with downsides including &amp;ldquo;interesting&amp;rdquo; new &amp;ldquo;features&amp;rdquo; and increased maintenance burden.&lt;/p&gt;

&lt;p&gt;Hopefully, starting with Linux 3.15 the ground was laid to safely transform any traceable kernel function into userland events. &amp;ldquo;Safely&amp;rdquo; is common computer science expression referring to &amp;ldquo;some virtual machine&amp;rdquo;. This case is no exception. Linux has had one for years. Since Linux 2.1.75 released in 1997 actually. It&amp;rsquo;s called Berkeley Packet Filter of BPF for short. As its name suggests, it was originally developed for the BSD firewalls. It had only 2 registers and only allowed forward jumps meaning that you could not write loops with it (Well, you can, if you know the maximum iterations and you manually unroll them). The point was to guarantee the program would always terminate and hence never hang the system. Still not sure if it has any use while you have iptables? It serves as the &lt;a href=&#34;https://blog.cloudflare.com/bpf-the-forgotten-bytecode/&#34;&gt;foundation of CloudFlare&amp;rsquo;s AntiDDos protection&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;OK, so, with Linux the 3.15, &lt;a href=&#34;TODO&#34;&gt;BPF was extended&lt;/a&gt; turning it into eBPF. For &amp;ldquo;extended&amp;rdquo; BPF. It upgrades from 2 32 bits registers to 10 64 bits 64 registers and adds backward jumping among others. It has then been &lt;a href=&#34;https://lwn.net/Articles/604043/&#34;&gt;further extended in Linux 3.18&lt;/a&gt; moving it out of the networking subsystem, and adding tools like maps. To preserve the safety guarantees, it &lt;a href=&#34;http://lxr.free-electrons.com/source/kernel/bpf/verifier.c#L21&#34;&gt;introduces a checker&lt;/a&gt; which validates all memory accesses and possible code path. If the checker can&amp;rsquo;t guarantee the code will terminate within fixed boundaries, it will deny the initial insertion of the program.&lt;/p&gt;

&lt;p&gt;For more history, there is &lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf&#34;&gt;an excellent Oracle presentation on eBPF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s get started.&lt;/p&gt;

&lt;h3 id=&#34;hello-from-from-inet-listen:30fe7a87f2e63f2b769ee3edffa56012&#34;&gt;Hello from from &lt;code&gt;inet_listen&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;As writing assembly is not the most convenient task, even for the best of us, we&amp;rsquo;ll use &lt;a href=&#34;https://github.com/iovisor/bcc&#34;&gt;bcc&lt;/a&gt;. bcc is a collection of tools based on LLVM and Python abstracting the underlying machinery. Probes are written in C and the results can be exploited from python allowing to easily write non trivial applications.&lt;/p&gt;

&lt;p&gt;Start by install bcc. For some of these examples, you may require a recent (read &amp;gt;= 4.4) version of the kernel. If you are willing to actually try these examples, I highly recommend that you setup a VM. &lt;em&gt;NOT&lt;/em&gt; a docker container. You can&amp;rsquo;t change the kernel in a container. As this is a young and dynamic projects, install instructions are highly platform/version dependant. You can find up to date instructions on &lt;a href=&#34;https://github.com/iovisor/bcc/blob/master/INSTALL.md&#34;&gt;https://github.com/iovisor/bcc/blob/master/INSTALL.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So, we want to get an event whenever a program starts to listen on TCP socket. When calling the &lt;code&gt;listen()&lt;/code&gt; syscall on a &lt;code&gt;AF_INET&lt;/code&gt; + &lt;code&gt;SOCK_STREAM&lt;/code&gt; socket, the underlying kernel function is &lt;a href=&#34;http://lxr.free-electrons.com/source/net/ipv4/af_inet.c#L194&#34;&gt;&lt;code&gt;inet_listen&lt;/code&gt;&lt;/a&gt;. We&amp;rsquo;ll start by hooking a &amp;ldquo;Hello World&amp;rdquo; &lt;code&gt;kprobe&lt;/code&gt; on it&amp;rsquo;s entrypoint.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bcc import BPF

# Hello BPF Program
bpf_text = &amp;quot;&amp;quot;&amp;quot; 
#include &amp;lt;net/inet_sock.h&amp;gt;
#include &amp;lt;bcc/proto.h&amp;gt;

// 1. Attach kprobe to &amp;quot;inet_listen&amp;quot;
int kprobe__inet_listen(struct pt_regs *ctx, struct socket *sock, int backlog)
{
    bpf_trace_printk(&amp;quot;Hello World!\\n&amp;quot;);
    return 0;
};
&amp;quot;&amp;quot;&amp;quot;

# 2. Build and Inject program
b = BPF(text=bpf_text)

# 3. Print debug output
while True:
    print b.trace_readline()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This program does 3 things:
1. It attaches a kernel probe to &amp;ldquo;inet_listen&amp;rdquo; using a naming convention. If the function was called, say, &amp;ldquo;my_probe&amp;rdquo;, it could be explicitly attached with &lt;code&gt;b.attach_kprobe(&amp;quot;inet_listen&amp;quot;, &amp;quot;my_probe&amp;quot;&lt;/code&gt;.
2. It builds the program using LLVM new BPF backend, inject the resulting bytecode using the (new) &lt;code&gt;bpf()&lt;/code&gt; syscall and automatically attaches the probes matching the naming convention.
3. It reads the raw output from the kernel pipe.&lt;/p&gt;

&lt;p&gt;Note: eBPF backend of LLVM is still young. If you think you&amp;rsquo;ve hit a bug, you may want to upgrade.&lt;/p&gt;

&lt;p&gt;Noticed the &lt;code&gt;bpf_trace_printk&lt;/code&gt; call? This is a stripped down version of the kernel&amp;rsquo;s &lt;code&gt;printk()&lt;/code&gt; debug function. When used, it produces tracing informations to a special kernel pipe in &lt;code&gt;/sys/kernel/debug/tracing/trace_pipe&lt;/code&gt;. As the name implies, this is a pipe. If multiple readers are consuming it, only 1 will get a given line. This makes it unsuitable for production.&lt;/p&gt;

&lt;p&gt;Fortunately, Linux 3.19 introduced maps for message passing and Linux 4.4 brings arbitrary perf events support. I&amp;rsquo;ll demo the perf event based approach later in this post.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# From a first console
ubuntu@bcc:~/dev/listen-evts$ sudo /python tcv4listen.py 
              nc-4940  [000] d... 22666.991714: : Hello World!
 
# From a second console
ubuntu@bcc:~$ nc -l 0 4242
^C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yay!&lt;/p&gt;

&lt;h3 id=&#34;grab-the-backlog:30fe7a87f2e63f2b769ee3edffa56012&#34;&gt;Grab the backlog&lt;/h3&gt;

&lt;p&gt;Now, let&amp;rsquo;s print some easily accessible data. Say the &amp;ldquo;backlog&amp;rdquo;. The backlog is the number of pending established TCP connections, pending to be &lt;code&gt;accept()&lt;/code&gt;ed.&lt;/p&gt;

&lt;p&gt;Just tweak a bit the &lt;code&gt;bpf_trace_printk&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;bpf_trace_printk(&amp;quot;Listening with with up to %d pending connections!\\n&amp;quot;, backlog);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you re-run the example with this world-changing improvement, you should see something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(bcc)ubuntu@bcc:~/dev/listen-evts$ sudo python tcv4listen.py 
              nc-5020  [000] d... 25497.154070: : Listening with with up to 1 pending connections!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;nc&lt;/code&gt; is a single connection program, hence the backlog of 1. Nginx or Redis would output 128 here. But that&amp;rsquo;s another story.&lt;/p&gt;

&lt;p&gt;Easy hue? Now let&amp;rsquo;s get the port.&lt;/p&gt;

&lt;h3 id=&#34;grab-the-port-and-ip:30fe7a87f2e63f2b769ee3edffa56012&#34;&gt;Grab the port and IP&lt;/h3&gt;

&lt;p&gt;Studying &lt;code&gt;inet_listen&lt;/code&gt; source from the kernel, we know that we need to get the &lt;code&gt;inet_sock&lt;/code&gt; from the &lt;code&gt;socket&lt;/code&gt; object. Just copy from the sources, and insert at the beginning of the tracer:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// cast types. Intermediate cast not needed, kept for readability
struct sock *sk = sock-&amp;gt;sk;
struct inet_sock *inet = inet_sk(sk);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The port can now be accessed from &lt;code&gt;inet-&amp;gt;inet_sport&lt;/code&gt; in network byte order (aka: Big Endian). Easy! So, we could just replace the &lt;code&gt;bpf_trace_printk&lt;/code&gt; with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;bpf_trace_printk(&amp;quot;Listening on port %d!\\n&amp;quot;, inet-&amp;gt;inet_sport);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then run:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ubuntu@bcc:~/dev/listen-evts$ sudo /python tcv4listen.py 
...
R1 invalid mem access &#39;inv&#39;
...
Exception: Failed to load BPF program kprobe__inet_listen
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Except that it&amp;rsquo;s not (yet) so simple. Bcc is improving a &lt;em&gt;lot&lt;/em&gt; currently. While writing this post, a couple of pitfalls had already been addressed. But not yet all. This Error means the in-kernel checker could prove the memory accesses in program are correct. See the explicit cast. We need to help is a little by making the accesses more explicit. We&amp;rsquo;ll use &lt;code&gt;bpf_probe_read&lt;/code&gt; trusted function to read an arbitrary memory location while guaranteeing all necessary checks are done with something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Explicit initialization. The &amp;quot;=0&amp;quot; part is needed to &amp;quot;give life&amp;quot; to the variable on the stack
u16 lport = 0;

// Explicit arbitrary memory access. Read it:
//    Read into &#39;lport&#39;, &#39;sizeof(lport)&#39; bytes from &#39;inet-&amp;gt;inet_sport&#39; memory location
bpf_probe_read(&amp;amp;lport, sizeof(lport), &amp;amp;(inet-&amp;gt;inet_sport));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reading the bound address for IPv4 is basically the same, using &lt;code&gt;inet-&amp;gt;inet_rcv_saddr&lt;/code&gt;. If we put is all together, we should get the backlog, the port and the bound IP:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bcc import BPF  
  
# BPF Program  
bpf_text = &amp;quot;&amp;quot;&amp;quot;   
#include &amp;lt;net/sock.h&amp;gt;  
#include &amp;lt;net/inet_sock.h&amp;gt;  
#include &amp;lt;bcc/proto.h&amp;gt;  
  
// Send an event for each IPv4 listen with PID, bound address and port  
int kprobe__inet_listen(struct pt_regs *ctx, struct socket *sock, int backlog)  
{  
    // Cast types. Intermediate cast not needed, kept for readability  
    struct sock *sk = sock-&amp;gt;sk;  
    struct inet_sock *inet = inet_sk(sk);  

    // Working values. You *need* to initialize them to give them &amp;quot;life&amp;quot; on the stack and use them afterward  
    u32 laddr = 0;  
    u16 lport = 0;  

    // Pull in details. As &#39;inet_sk&#39; is internally a type cast, we need to use &#39;bpf_probe_read&#39;  
    // read: load into &#39;laddr&#39; &#39;sizeof(laddr)&#39; bytes from address &#39;inet-&amp;gt;inet_rcv_saddr&#39;  
    bpf_probe_read(&amp;amp;laddr, sizeof(laddr), &amp;amp;(inet-&amp;gt;inet_rcv_saddr));  
    bpf_probe_read(&amp;amp;lport, sizeof(lport), &amp;amp;(inet-&amp;gt;inet_sport));  

    // Push event
    bpf_trace_printk(&amp;quot;Listening on %x %d with %d pending connections\\n&amp;quot;, ntohl(laddr), ntohs(lport), backlog);  
    return 0;
};  
&amp;quot;&amp;quot;&amp;quot;  
  
# Build and Inject BPF  
b = BPF(text=bpf_text)  
  
# Print debug output  
while True:  
  print b.trace_readline()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A test run should output something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(bcc)ubuntu@bcc:~/dev/listen-evts$ sudo python tcv4listen.py 
              nc-5024  [000] d... 25821.166286: : Listening on 7f000001 4242 with 1 pending connections
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Provided that you listen on localhost. The address is displayed as hex here to avoid dealing with the IP pretty printing but that&amp;rsquo;s all wired. And that&amp;rsquo;s cool.&lt;/p&gt;

&lt;p&gt;Note: you may wonder why &lt;code&gt;ntohs&lt;/code&gt; and &lt;code&gt;ntohl&lt;/code&gt; can be called from BPF while they are not trusted. This is because they are macros and inline functions from &amp;ldquo;.h&amp;rdquo; files and a small bug was &lt;a href=&#34;https://github.com/iovisor/bcc/pull/453&#34;&gt;fixed&lt;/a&gt; while writing this post.&lt;/p&gt;

&lt;p&gt;All done, one more piece: We want to get the related container. In the context of networking, that&amp;rsquo;s means we want the network namespace. The network namespace being the building block of containers allowing them to have isolated networks.&lt;/p&gt;

&lt;h3 id=&#34;grab-the-network-namespace-a-forced-introduction-to-perf-events:30fe7a87f2e63f2b769ee3edffa56012&#34;&gt;Grab the network namespace: a forced introduction to perf events&lt;/h3&gt;

&lt;p&gt;On the userland, the network namespace can be determined by checking the target of &lt;code&gt;/proc/PID/ns/net&lt;/code&gt;. It should look like &lt;code&gt;net:[4026531957]&lt;/code&gt;. The number between brackets is the inode number of the network namespace. This said, we could grab it by scrapping &amp;lsquo;/proc&amp;rsquo; but this is racy, we may be dealing with short-lived processes. And races are never good. We&amp;rsquo;ll grab the inode number directly from the kernel. Fortunately, that&amp;rsquo;s an easy one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Create an populate the variable
u32 netns = 0;

// Read the netns inode number, like /proc does
netns = sk-&amp;gt;__sk_common.skc_net.net-&amp;gt;ns.inum;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Easy. And it works.&lt;/p&gt;

&lt;p&gt;But if you&amp;rsquo;ve read so far, you may guess there is something wrong somewhere. And there is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;bpf_trace_printk(&amp;quot;Listening on %x %d with %d pending connections in container %d\\n&amp;quot;, ntohl(laddr), ntohs(lport), backlog, netns);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you try to run it, you&amp;rsquo;ll get some cryptic error message:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(bcc)ubuntu@bcc:~/dev/listen-evts$ sudo python tcv4listen.py
error: in function kprobe__inet_listen i32 (%struct.pt_regs*, %struct.socket*, i32)
too many args to 0x1ba9108: i64 = Constant&amp;lt;6&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What clang is trying to tell you is &amp;ldquo;Hey pal, &lt;code&gt;bpf_trace_printk&lt;/code&gt; can only take 4 arguments, you&amp;rsquo;ve just used 5.&amp;ldquo;. I won&amp;rsquo;t dive into the details here, but that&amp;rsquo;s a BPF limitation. If you want to dig it, &lt;a href=&#34;http://lxr.free-electrons.com/source/kernel/trace/bpf_trace.c#L86&#34;&gt;here is a good starting point&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The only way to fix it is to&amp;hellip; stop debugging and make it production ready. So let&amp;rsquo;s get started (and make sure run at least Linux 4.4). We&amp;rsquo;ll use perf events which supports passing arbitrary sized structures to userland. Additionally, only our reader will get it so that multiple unrelated eBPF programs can produce data concurrently without issues.&lt;/p&gt;

&lt;p&gt;To use it, we need to:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;define a structure&lt;/li&gt;
&lt;li&gt;declare the event&lt;/li&gt;
&lt;li&gt;push the event&lt;/li&gt;
&lt;li&gt;re-declare the event on Python&amp;rsquo;s side (This step should go away in the future)&lt;/li&gt;
&lt;li&gt;consume and format the event&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This may seem like a lot, but it ain&amp;rsquo;t. See:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// At the begining of the C program, declare our event
struct listen_evt_t {
    u64 laddr;
    u64 lport;
    u64 netns;
    u64 backlog;
};
BPF_PERF_OUTPUT(listen_evt);

// In kprobe__inet_listen, replace the printk with
struct listen_evt_t evt = {
    .laddr = ntohl(laddr),
    .lport = ntohs(lport),
    .netns = netns,
    .backlog = backlog,
};
listen_evt.perf_submit(ctx, &amp;amp;evt, sizeof(evt));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python side will require a little more work, though:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# We need ctypes to parse the event structure
import ctypes

# Declare data format
class ListenEvt(ctypes.Structure):
    _fields_ = [
        (&amp;quot;laddr&amp;quot;,   ctypes.c_ulonglong),
        (&amp;quot;lport&amp;quot;,   ctypes.c_ulonglong),
        (&amp;quot;netns&amp;quot;,   ctypes.c_ulonglong),
        (&amp;quot;backlog&amp;quot;, ctypes.c_ulonglong),
    ]

# Declare event printer
def print_event(cpu, data, size):
    event = ctypes.cast(data, ctypes.POINTER(ListenEvt)).contents
    print(&amp;quot;Listening on %x %d with %d pending connections in container %d&amp;quot; % (
        event.laddr,
        event.lport,
        event.backlog,
        event.netns,
    ))

# Replace the event loop
b[&amp;quot;listen_evt&amp;quot;].open_perf_buffer(print_event)
while True:
    b.kprobe_poll()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Give it a try. In this example, I have a redis running in a docker container and nc on the host:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(bcc)ubuntu@bcc:~/dev/listen-evts$ sudo python tcv4listen.py
Listening on 0 6379 with 128 pending connections in container 4026532165
Listening on 0 6379 with 128 pending connections in container 4026532165
Listening on 7f000001 6588 with 1 pending connections in container 4026531957
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;last-word:30fe7a87f2e63f2b769ee3edffa56012&#34;&gt;Last word&lt;/h3&gt;

&lt;p&gt;Absolutely everything is now setup to use trigger events from arbitrary function calls in the kernel using eBPF, and you should have seen most of the common pitfalls I hit while learning eBPF. If you want to see the full version of this tool, along with some more tricks like IPv6 support, have a look at &lt;a href=&#34;https://github.com/iovisor/bcc/blob/master/tools/solisten.py&#34;&gt;https://github.com/iovisor/bcc/blob/master/tools/solisten.py&lt;/a&gt;. It&amp;rsquo;s now an official tool, thanks to the support of the bcc team.&lt;/p&gt;

&lt;p&gt;To go further, you may want to checkout Brendan Gregg&amp;rsquo;s blog, in particular &lt;a href=&#34;http://www.brendangregg.com/blog/2015-05-15/ebpf-one-small-step.html&#34;&gt;the post about eBPF maps and statistics&lt;/a&gt;. He his one of the project&amp;rsquo;s main contributor.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>